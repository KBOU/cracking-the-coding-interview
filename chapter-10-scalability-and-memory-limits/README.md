# スケーラビリティ

問題は以下のステップにそって解くと良いようです。

1. とりあえずスケーラビリティの問題はないとして解いてみる
2. スケーラビリティを考えた時に浮き彫りになる問題を洗い出す
3. 解く


## スケーラビリティの問題を洗い出す

* HDの容量
* メモリ
* ネットワークディレイ

あたりの観点で洗い出す

## データの分割

* データが現れた順にサーバに入れて、サーバがいっぱいになったら次のサーバに・・・
* ハッシュで分ける(サーバを増やすときめんどくさい)
* 値にもとづいて分ける(地域とか)
* 適当

# 10-1. 1,000クライアントに株価を提供するサービス

INPUT

* 株価データ(毎営業日更新)

OUTPUT

* 四本値株価

観点

* 信頼性
    * 可用性
    * データが最新
* 性能効率性
    * 更新負荷
    * 参照負荷
* 操作性
    * レスポンスタイム
    * データの応用が楽
* セキュリティ
    * 認証
* 互換性
* 保守性
    * サーバの拡張が楽
* 移行容易性


提案：

必要なマシン

* DBサーバ2台
* Webサーバ2台
* Load Balancer 1台


* DBサーバ
    * 1台をマスタにしてもう一台をレプリカにする
    * 一日一回バッチを回してマスタを更新する。負荷にもよるがマスタと同じサーバでやる
* Webサーバ
    * GETでのアクセスのみ受付
    * URLパラメータの解釈
    * シグニチャーの突合
    * レプリカからデータを取得
    * JSONで返す


対案としてDBを直接参照する手法もあると思うが、  
その場合権限を適切に設定しないとデータが勝手に更新されてしまう恐れ、
ユーザがSQLを知っている必要があるし、データを取得してからの応用がめんどくさい。


## 10-2. FacebookやLinkedinなどの大規模システムで友達関係を表示するアルゴリズムを設計

### STEP1 まずは制約を考えずに

人をクラスにして友達リストみたいなのを持ってればいい。  
そこから探す

### STEP2 制約条件を考える

人数がむちゃくちゃ多くなった場合、  
 一つのサーバで全員管理できなくなる。

### STEP3 制約条件を踏まえて解いてみる

STEP2より、複数サーバにわけなくてはダメ。  
ということでどのサーバに友だちがいるかを友達IDでわかるようにしないとダメ。

手順

1. 友達IDを受け付ける
2. まずはサーバを友達IDから取得する
3. サーバから友達を取得する


## 10-3. ファイルに書かれた4 billionのintの中から存在しないintを返す。

### STEP1 まずは制約なしで(いや1GBの制約で)

ファイルを頭から読み込んで、抜けてる数値を配列に入れればできるのでは・・・  
と思いましたが、だめなのかなー。答えみても最初に見つけたやつ返してるように見えるし・・・  
まあいいです。

4 billionのintだと存在しないintの数は3億弱になる。
intは4バイトなので、4x3億 &gt; 1GB

4billion個のintを1GB(8billion bits)のbitfieldにいれて管理することにする。  
そうするとbitfieldの位置がintの値となり、フラグが立っていれば存在するということになる。

### STEP2 制約条件を考えてみる(メモリ10MB)

上述のやり方だと、500MBでできるが10MBにははるかに及ばない・・・  
なのでメモリ使用量を減らすやり方を考えなければならない。

アルゴリズムを2ステップに分解する。

### STEP3 制約条件を踏まえてみる

最初のステップでファイルに存在するintを1,048,576ずつブロックに分けて集計する。
そしたら4096個のブロックが出来上がるわけだが、各ブロックで集計結果が1,048,576に満たなかった場合は、  
そのブロックに抜けがあるということが判明する。

そしてそのブロック内の範囲で抜けている値を探し出す。

`src/find_non_existed_int.py`


## 10-4. 1からNまでの整数が入っている配列がある。その中で重複したエントリーをすべて洗い出して表示する。

条件

* Nはいくつかわからない
* N &le; 32,000
* メモリは4KBまで


### 方針

bitfieldを使うN %le; 32,000なので4KBあれば足りる。(厳密に言うと足りないかもしれないがその場合は10-4と同じように分割すればよい)

arrayを頭から読んでいき、対応するbitfieldにフラグを立てる。  
bitfieldにフラグがすでに立っている場合はフラグをいじらずにprintする。

`src/find_dup.py`


## 10-5. クローラーを実装するときに無限ループをどうやって回避するか？

### STEP1. まずはページ数が十分少ないと仮定する。

無限ループが起こるのは、ページ間のリンクがループしているからなので、  
一度訪れたページは記憶し、再び訪れないようにすれば無限ループは起こらない。


### STEP2. 大量のページが存在する。

この場合、ひとつのサーバで訪れたページを全部記憶するのは難しそう。

### STEP3. どうしよう

URLからドメインを取得しドメインからIPそして地域を抽出し、  
そのURLに関してはその地域担当のクローラにクロールしてもらうことにする。

そうすれば自分が担当する地域のみ訪れたかどうかを把握していれば良い

### 追記

全然違った。

URLにはGETパラメータが含まれるケースも有り、  
無意味なGETパラメータが含まれていた場合、
URLでページが同一かどうか認識していたら、無限ループする可能性がある。

ということなので、URLとコンテンツの中身を判断して識別する必要があるとのことです。

URLとコンテンツから一意に決められたシグニチャーのページがすでに訪問済みであれば、  
優先順位を下げてQueueにぶちこむ。  
訪問済みでなければ、次回イテレーションでクロールする。


## 10-6. 10億個のURLを記憶し重複を探す


## STEP1. 10個のURLとする

URLがkeyのHashMapに入れてカウントが1より大きくなったら重複とする

## STEP2. 10億個のケースを考えてみる。

一個のURLが平均70文字とすると、
70x10億 = 70GBなので、メモリ上に持つことは不可能

## STEP3. どうする？

方法として2パターンあるはず。

1. メモリでなくファイルで持つ
2. 複数のマシンのメモリ上に持つ。

しかし、2の場合はどんだけサーバ必要やねんということになるので、
まーなしだろう。

よって1の方法で行く。

といっても1つのファイルで70GBは無理かも。(ファイルシステムによってはいけるよう)。  
いずれにせよ、読み込みに時間がかかるので適度に分割したほうが良さそう。

URLをhashにしてそれをファイル名にすればいいのではないだろうか。  
hashがぶつかる可能性もあるので、ファイルの中身は、

* URL
* 出現回数

をURLごとに1行ずつ増やしていく感じだろうか。

## 10-7. キャッシュを使ってサーチシステムのレスポンスを上げる。そしてキャッシュをうまいことアップデートする

問題がややこしいなー・・・  
100個のサーバ群(A)がLBかなんかに管理されてて、ユーザのサーチクエリに反応して、
その100個の各々にたくさんマシン(B)がくっついているイメージだろうか・・・  


現状の課題：

* processSearchは遅いのでキャッシュしたい
* Bはランダムに選ばれるのでそいつにprocessSearchの結果をキャッシュしても意味が無い


解決法としては

1. Aにキャッシュする
2. ストレージサーバ(Memcachedとか)のクラスタを作ってそこにキャッシュする

2の方がスケールしやすいので2にする。


検索のプロセス

AはBにprocessSearchで問い合わせる前にストレージサーバでqueryをキーとするレコードを取得する。  
なかったらBに問い合わせる。

結果の更新のプロセス

検索結果が更新されたら、ストレージサーバクラスタをクローリングして更新する


### 追記

* LRUから消していく仕組みが漏れていた
* キャシュをExpireする仕組みがないと、検索結果に新しいURLが入ってきたケースは対応が難しい



